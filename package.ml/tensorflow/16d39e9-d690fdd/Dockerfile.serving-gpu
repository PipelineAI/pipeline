FROM fluxcapacitor/gpu-cuda8-cudnn6-16.04:master

WORKDIR /root

ENV \
  TERM=xterm

###################
# Setup OpenJDK 1.8
###################
RUN \
  apt-get update \
  && apt-get install -y software-properties-common \
  && add-apt-repository -y ppa:openjdk-r/ppa \
  && apt-get update \
  && apt-get install -y --no-install-recommends openjdk-8-jdk openjdk-8-jre-headless \
  && apt-get install -y apt-transport-https \
  && apt-get install -y wget \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*

ENV \
  JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/


###################
# Setup Bazel 0.5.2 (required due to https://github.com/tensorflow/tensorflow/issues/11884)
###################
ENV \
  BAZEL_VERSION=0.5.2

# Running bazel inside a `docker build` command causes trouble, cf:
#   https://github.com/bazelbuild/bazel/issues/134
# The easiest solution is to set up a bazelrc file forcing --batch.
RUN echo "startup --batch" >> /etc/bazel.bazelrc

# Similarly, we need to workaround sandboxing issues:
#   https://github.com/bazelbuild/bazel/issues/418
RUN echo "build --spawn_strategy=standalone --genrule_strategy=standalone" \
    >> /etc/bazel.bazelrc
ENV BAZELRC /etc/bazel.bazelrc

# Install the most recent bazel release.
RUN mkdir /root/bazel && \
    cd /root/bazel && \
    curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh && \
    chmod a+x bazel-*.sh && \
    ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh && \
    rm -f bazel-$BAZEL_VERSION-installer-linux-x86_64.sh


##########################
# Build TensorFlow Serving
##########################
ENV \
  TENSORFLOW_SERVING_VERSION=0.6.0 \
  TENSORFLOW_SERVING_HOME=/root/serving 

# Required by TensorFlow Serving
# Inspired by the following:
#   https://alliseesolutions.wordpress.com/2016/09/08/install-gpu-tensorflow-from-sources-w-ubuntu-16-04-and-cuda-8-0/
#   https://github.com/tensorflow/serving/blob/1697e743b5a001d0f79274d94d2d8d570a09865b/tensorflow_serving/tools/docker/Dockerfile.devel-gpu
RUN \
  apt-get update \
  && apt-get install -y \
        build-essential \
        curl \
        libcurl3-dev \
        git \
        libfreetype6-dev \
        libpng12-dev \
        libzmq3-dev \
        pkg-config \
        python-dev \
        python3-dev \
        python-numpy \
        python3-numpy \
        python-six \
        python3-six \
        python-wheel \
        python3-wheel \
        python-pip \
        python3-pip \
        software-properties-common \
        swig \
        zip \
        zlib1g-dev \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*

# Install Anaconda with Python3 
RUN wget -q https://repo.continuum.io/miniconda/Miniconda3-4.3.21-Linux-x86_64.sh -O /tmp/miniconda.sh  && \
    echo 'c1c15d3baba15bf50293ae963abef853 */tmp/miniconda.sh' | md5sum -c - && \
    bash /tmp/miniconda.sh -f -b -p /opt/conda && \
    /opt/conda/bin/conda install --yes python=3.6 sqlalchemy tornado jinja2 traitlets requests pip && \
    /opt/conda/bin/pip install --upgrade pip && \
    rm /tmp/miniconda.sh

ENV \
  PATH=/opt/conda/bin:$PATH

RUN \
  pip install --upgrade pip

RUN \
  pip install grpcio

RUN \
  conda install --yes openblas scikit-learn numpy scipy matplotlib pandas seaborn

# Clone Tensorflow Serving and the Tensorflow Submodule
RUN \
 cd ~ \
 && git clone --recurse-submodules https://github.com/tensorflow/serving.git \
 && cd $TENSORFLOW_SERVING_HOME \
 && git reset --hard d690fdd 

# Config inspired by the following:
#    http://ci.tensorflow.org/job/tensorflow-master-linux-gpu/2421/consoleText

RUN cp -P /usr/include/cudnn.h /usr/local/cuda/include
RUN cp -P /usr/lib/x86_64-linux-gnu/libcudnn* /usr/local/cuda/lib64
ENV LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH

ENV TF_NEED_CUDA=1
ENV TF_NEED_GCP=0
ENV TF_NEED_JEMALLOC=1
ENV TF_NEED_HDFS=1
ENV TF_NEED_OPENCL=0
ENV TF_ENABLE_XLA=0
ENV TF_CUDA_VERSION=8.0
ENV TF_CUDNN_VERSION=6
ENV CUDA_PATH="/usr/local/cuda"
ENV CUDA_TOOLKIT_PATH=$CUDA_PATH
ENV CUDNN_INSTALL_PATH=$CUDA_PATH
ENV PYTHON_BIN_PATH=/opt/conda/bin/python3.6
ENV PYTHON_LIB_PATH=/opt/conda/lib/python3.6
ENV CI_BUILD_PYTHON=$PYTHON_BIN_PATH
ENV CC_OPT_FLAGS="-march=native"
ENV TF_CUDA_COMPUTE_CAPABILITIES=3.7
####################
###      AWS     ###
##  P2 Instances  ##
# Tesla K-80 (3.7) #
#                  #
##  G2 Instances  ##
# GRID K520 (3.5)  #
#                  #
###  Google GCP  ###   
# Tesla K-80 (3.7) #
####################

RUN \
  cd $TENSORFLOW_SERVING_HOME/tensorflow \
  && tensorflow/tools/ci_build/builds/configured GPU

RUN \
  cd $TENSORFLOW_SERVING_HOME \
  # Remove NCCL since it isn't building properly
  && sed -i.bak '/nccl/d' tensorflow/tensorflow/contrib/BUILD \
  && bazel build -c opt --config=cuda \
      --verbose_failures \
      --spawn_strategy=standalone --genrule_strategy=standalone \
      --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.1 --copt=-msse4.2 \
      --crosstool_top=@local_config_cuda//crosstool:toolchain \
       tensorflow_serving/... \
  && chmod a+x bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \
  && cp bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server /usr/local/bin/ \
  && bazel clean --expunge

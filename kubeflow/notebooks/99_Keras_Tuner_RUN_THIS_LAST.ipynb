{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING\n",
    "# DO NOT RUN THIS NOTEBOOK UNTIL YOU ARE DONE WITH THE REST OF THE WORKSHOP\n",
    "THIS WILL INSTALL TENSORFLOW 2.0 WHICH WILL MESS UP THE REST OF THE ENVIRONMENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf keras-tuner\n",
    "git clone https://github.com/keras-team/keras-tuner.git\n",
    "cd keras-tuner\n",
    "git reset --hard fa47f90729237d255f41a654bb174822b43a391b\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y tensorflow==1.13.1\n",
    "!pip install tensorflow==2.0.0-beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hypermodel import HyperModel\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "\n",
    "(x, y), (val_x, val_y) = keras.datasets.mnist.load_data()\n",
    "x = x.astype('float32') / 255.\n",
    "val_x = val_x.astype('float32') / 255.\n",
    "\n",
    "x = x[:10000]\n",
    "y = y[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to perform hyperparameter tuning for a single-layer dense neural network using random search.\n",
    "\n",
    "First, we define a model-building function. It takes an argument hp from which you can sample hyperparameters, such as hp.Range('units', min_value=32, max_value=512, step=32) (an integer from a certain range)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case #1:  Basic\n",
    "- Define a `build_model` function\n",
    "- Returns a compiled model\n",
    "- Use hyperparameters defined on the fly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search space may contain conditional hyperparameters.\n",
    "\n",
    "Below, we have a for loop creating a tunable number of layers, which themselves involve a tunable units parameter.\n",
    "\n",
    "This can be pushed to any level of parameter interdependency, including recursion.\n",
    "\n",
    "Note that all parameter names should be unique (here, in the loop over i, we name the inner parameters 'units_' + str(i))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "    for i in range(hp.Range('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Range('units_' + str(i), 32, 512, 32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, instantiate a tuner. You should specify the model-building function, the name of the objective to optimize (whether to minimize or maximize is automatically inferred for built-in metrics), the total number of trials (max_trials) to test, and the number of models that should be built and fit for each trial (executions_per_trial).\n",
    "\n",
    "Available tuners are RandomSearch and Hyperband.\n",
    "\n",
    "Note: the purpose of having multiple executions per trial is to reduce results variance and therefore be able to more accurately assess the performance of a model. If you want to get results faster, you could set executions_per_trial=1 (single round of training for each model configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuner-results',\n",
    "    project_name='helloworld_case_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print a summary of the search space:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, start the search for the best hyperparameter configuration. The call to search has the same signature as model.fit().\n",
    "\n",
    "Here's what happens in search: models are built iteratively by calling the model-building function, which populates the hyperparameter space (search space) tracked by the hp object. The tuner progressively explores the space, recording metrics for each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x=x,\n",
    "             y=y,\n",
    "             epochs=3,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When search is over, you can retrieve the best model(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or print a summary of the results:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also find detailed logs and checkpoints in the folder `tuner-results`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al tuner-results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case #2:\n",
    "- Override the loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(name='my_loss'),\n",
    "    metrics=['accuracy', 'mse'],\n",
    "    max_trials=5,\n",
    "    directory='tuner-results',\n",
    "    project_name='helloworld_case_2')\n",
    "\n",
    "tuner.search(x, y,\n",
    "             epochs=5,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case #3:\n",
    "- We define a custom HyperModel subclass instead of model-building function\n",
    "- This makes it easy to share and reuse hypermodels.\n",
    "- A HyperModel subclass only needs to implement a build(self, hp) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(HyperModel):\n",
    "\n",
    "    def __init__(self, img_size, num_classes):\n",
    "        self.img_size = img_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Flatten(input_shape=self.img_size))\n",
    "        for i in range(hp.Range('num_layers', 2, 20)):\n",
    "            model.add(layers.Dense(units=hp.Range('units_' + str(i), 32, 512, 32),\n",
    "                                   activation='relu'))\n",
    "        model.add(layers.Dense(self.num_classes, activation='softmax'))\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    MyHyperModel(img_size=(28, 28), num_classes=10),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    directory='tuner-results',\n",
    "    project_name='helloworld_case_3')\n",
    "\n",
    "tuner.search(x,\n",
    "             y=y,\n",
    "             epochs=5,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case #4:\n",
    "- Restrict the search space\n",
    "- Use default values for params that are left out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HyperParameters()\n",
    "hp.Choice('learning_rate', [1e-1, 1e-3])\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    max_trials=5,\n",
    "    hyperparameters=hp,\n",
    "    tune_new_entries=False,\n",
    "    objective='val_accuracy',\n",
    "    directory='tuner-results',\n",
    "    project_name='helloworld_case_4')\n",
    "\n",
    "tuner.search(x=x,\n",
    "             y=y,\n",
    "             epochs=5,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case #5:\n",
    "- We override specific parameters with fixed values that aren't the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HyperParameters()\n",
    "hp.Fixed('learning_rate', 0.1)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    max_trials=5,\n",
    "    hyperparameters=hp,\n",
    "    tune_new_entries=True,\n",
    "    objective='val_accuracy',\n",
    "    directory='tuner-results',\n",
    "    project_name='helloworld_case_5')\n",
    "\n",
    "tuner.search(x=x,\n",
    "             y=y,\n",
    "             epochs=5,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case #6:\n",
    "- We reparameterize the search space\n",
    "- This means that we override the distribution of specific hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HyperParameters()\n",
    "hp.Choice('learning_rate', [1e-1, 1e-3])\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    max_trials=5,\n",
    "    hyperparameters=hp,\n",
    "    tune_new_entries=True,\n",
    "    objective='val_accuracy',\n",
    "    directory='tuner-results',\n",
    "    project_name='helloworld_case_6')\n",
    "\n",
    "tuner.search(x=x,\n",
    "             y=y,\n",
    "             epochs=5,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case #7:\n",
    "- We predefine the search space\n",
    "- No unregistered parameters are allowed in `build`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HyperParameters()\n",
    "hp.Choice('learning_rate', [1e-1, 1e-3])\n",
    "hp.Range('num_layers', 2, 20)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "    for i in range(hp.get('num_layers')):\n",
    "        model.add(layers.Dense(32,\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.get('learning_rate')),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    max_trials=5,\n",
    "    hyperparameters=hp,\n",
    "    allow_new_entries=False,\n",
    "    objective='val_accuracy',\n",
    "    directory='tuner-results',\n",
    "    project_name='helloworld_case_7')\n",
    "\n",
    "tuner.search(x=x,\n",
    "             y=y,\n",
    "             epochs=5,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Tuner includes pre-made tunable applications: HyperResNet and HyperXception.\n",
    "    \n",
    "These are ready-to-use hypermodels for computer vision.\n",
    "\n",
    "They come pre-compiled with loss=\"categorical_crossentropy\" and metrics=[\"accuracy\"].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.applications import HyperResNet\n",
    "from kerastuner.tuners import Hyperband\n",
    "\n",
    "hypermodel = HyperResNet(input_shape=(128, 128, 3), classes=10)\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=40,\n",
    "    directory='tuner-results',\n",
    "    project_name='hyper_resnet')\n",
    "\n",
    "tuner.search(x, y,\n",
    "             epochs=20,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily restrict the search space to just a few parameters\n",
    "\n",
    "If you have an existing hypermodel, and you want to search over only a few parameters (such as the learning rate), you can do so by passing a hyperparameters argument to the tuner constructor, as well as tune_new_entries=False to specify that parameters that you didn't list in hyperparameters should not be tuned. For these parameters, the default value gets used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import HyperParameters\n",
    "from kerastuner.applications import HyperXception\n",
    "\n",
    "hypermodel = HyperXception(input_shape=(128, 128, 3), classes=10)\n",
    "\n",
    "hp = HyperParameters()\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    hyperparameters=hp,\n",
    "    # `tune_new_entries=False` prevents unlisted parameters from being tuned\n",
    "    tune_new_entries=False,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=40,\n",
    "    directory='tuner-results',\n",
    "    project_name='hyper_xception_1')\n",
    "\n",
    "tuner.search(x, y,\n",
    "             epochs=20,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to know what parameter names are available? Read the code.\n",
    "\n",
    "About parameter default values: \n",
    "- Whenever you register a hyperparameter inside a model-building function or the build method of a hypermodel, you can specify a default value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.Range('units',\n",
    "         min_value=32,\n",
    "         max_value=512,\n",
    "         step=32,\n",
    "         default=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't, hyperparameters always have a default default (for Range, it is equal to min_value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing values in a hypermodel:\n",
    "- What if you want to do the reverse -- tune all available parameters in a hypermodel, except one (the learning rate)?\n",
    "- Pass a hyperparameters argument with a Fixed entry (or any number of Fixed entries), and specify tune_new_entries=True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = HyperXception(input_shape=(128, 128, 3), classes=10)\n",
    "\n",
    "hp = HyperParameters()\n",
    "hp.Fixed('learning_rate', value=1e-4)\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    hyperparameters=hp,\n",
    "    tune_new_entries=True,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=40,\n",
    "    directory='tuner-results',\n",
    "    project_name='hyper_xception_2')\n",
    "\n",
    "tuner.search(x, y,\n",
    "             epochs=20,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overriding compilation arguments\n",
    "- If you have a hypermodel for which you want to change the existing optimizer, loss, or metrics, you can do so by passing these arguments to the tuner constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = HyperXception(input_shape=(128, 128, 3), classes=10)\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss='mse',\n",
    "    metrics=[keras.metrics.Precision(name='precision'),\n",
    "             keras.metrics.Recall(name='recall')],\n",
    "    objective='val_precision',\n",
    "    max_trials=40,\n",
    "    directory='tuner-results',\n",
    "    project_name='hy_xception_3')\n",
    "\n",
    "tuner.search(x, y,\n",
    "             epochs=20,\n",
    "             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

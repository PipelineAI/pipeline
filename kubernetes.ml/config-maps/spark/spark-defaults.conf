# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Shell variables don't work here
# While we could hard-code to the value of this variable,
#   we're specifying --jars on the command line instead.
# This maintains the variable nature of this value.
# This needs to be done for anything that uses spark-submit.
#   ie. spark-sql, spark-shell, spark-submit, etc.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

spark.port.maxRetries                                         5000
spark.shuffle.sort.initialBufferSize                          4194304
spark.shuffle.file.buffer                                     1m
spark.unsafe.sorter.spill.reader.buffer.size                  2m
spark.shuffle.io.backLog                                      8192
spark.shuffle.io.serverThreads                                128
spark.shuffle.service.enabled                                 false
spark.dynamicAllocation.enabled                               false
spark.dynamicAllocation.minExecutors                          1
spark.dynamicAllocation.maxExecutors                          4
spark.deploy.defaultCores                                     1
#spark.eventLog.enabled                                        true
#spark.eventLog.dir                                            /root/events/
#spark.history.fs.logDirectory                                 /root/history/
#spark.history.ui.port                                         5050
spark.sql.parquet.filterPushdown                              true
spark.sql.parquet.cacheMetadata                               true
spark.sql.parquet.mergeSchema                                 false
spark.hadoop.parquet.enable.summary-metadata                  false
spark.sql.orc.filterPushdown                                  true
spark.sql.orc.splits.include.file.footer                      true
spark.sql.orc.cache.stripe.details.size                       10000
spark.speculation                                             false
spark.hadoop.mapreduce.fileoutputcommitter.cleanup.skipped    true
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version  2
spark.hadoop.fs.s3a.readahead.range                           157810688
spark.hadoop.fs.s3a.experimental.input.fadvise                random
spark.hadoop.fs.s3a.fast.output.enable                        true
spark.sql.hive.metastorePartitionPruning                      true
spark.sql.inMemoryColumnarStorage.partitionPruning            true
spark.cassandra.output.ignoreNulls                            true
spark.enable.hive.support                                     true

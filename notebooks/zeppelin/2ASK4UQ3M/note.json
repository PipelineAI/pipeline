{
  "paragraphs": [
    {
      "text": "%md # Start the Kafka Spark Streaming Job\n* ### This is optional.\n* ### Alternatively, use $PIPELINE_HOME/flux-start-kafka-streaming-likes.sh",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435352774943_904665808",
      "id": "20150626-210614_464619583",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch1\u003eStart the Kafka Spark Streaming Job\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ch3\u003eThis is optional.\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ch3\u003eAlternatively, use $PIPELINE_HOME/flux-start-kafka-streaming-likes.sh\u003c/h3\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Jun 26, 2015 9:06:14 PM",
      "dateStarted": "Oct 6, 2015 11:18:18 PM",
      "dateFinished": "Oct 6, 2015 11:18:18 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%dep\nz.reset()\nz.addRepo(\"maven central\").url(\"search.maven.org\")\nz.load(\"com.datastax.spark:spark-cassandra-connector_2.10:1.4.0\")\nz.load(\"org.elasticsearch:elasticsearch-spark_2.10:2.1.0\")\nz.load(\"com.databricks:spark-csv_2.10:1.2.0\")\nz.load(\"org.apache.spark:spark-streaming-kafka-assembly_2.10:1.4.1\")",
      "dateUpdated": "Oct 7, 2015 1:06:07 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorHide": false,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1438110093664_1508237074",
      "id": "20150728-190133_576357566",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "Must be used before SparkInterpreter (%spark) initialized"
      },
      "dateCreated": "Jul 28, 2015 7:01:33 PM",
      "dateStarted": "Oct 7, 2015 1:09:56 AM",
      "dateFinished": "Oct 7, 2015 1:09:56 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Configure Kafka",
      "text": "val brokers \u003d \"demo.fluxcapacitor.com:39092,demo.fluxcapacitor.com:39093\";\rval topicsSet \u003d Set(\"likes\");\rval kafkaParams \u003d Map[String, String](\"metadata.broker.list\" -\u003e brokers);",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435351067462_-362700882",
      "id": "20150626-203747_286831760",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "brokers: String \u003d demo.fluxcapacitor.com:39092,demo.fluxcapacitor.com:39093\ntopicsSet: scala.collection.immutable.Set[String] \u003d Set(likes)\nkafkaParams: scala.collection.immutable.Map[String,String] \u003d Map(metadata.broker.list -\u003e demo.fluxcapacitor.com:39092,demo.fluxcapacitor.com:39093)\n"
      },
      "dateCreated": "Jun 26, 2015 8:37:47 PM",
      "dateStarted": "Oct 6, 2015 11:18:19 PM",
      "dateFinished": "Oct 6, 2015 11:18:35 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Create the Kafka Stream",
      "text": "import org.apache.spark.streaming.kafka.KafkaUtils\nimport org.apache.spark.streaming.Seconds\nimport org.apache.spark.streaming.StreamingContext\nimport kafka.serializer.StringDecoder\n\ndef create(): StreamingContext \u003d {\n  @transient val newSsc \u003d new StreamingContext(sc, Seconds(2))\n  println(s\"Creating new StreamingContext $newSsc\")\n\n  newSsc\n}\n\nval ssc \u003d StreamingContext.getActiveOrCreate(create)\n\nval cassandraConfig \u003d Map(\"keyspace\" -\u003e \"fluxcapacitor\", \"table\" -\u003e \"real_time_likes\")\nval likeStream \u003d KafkaUtils.createDirectStream[String, String, StringDecoder, StringDecoder](ssc, kafkaParams, topicsSet)",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435352502700_1656285081",
      "id": "20150626-210142_283675308",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.streaming.kafka.KafkaUtils\nimport org.apache.spark.streaming.Seconds\nimport org.apache.spark.streaming.StreamingContext\nimport kafka.serializer.StringDecoder\ncreate: ()org.apache.spark.streaming.StreamingContext\nCreating new StreamingContext org.apache.spark.streaming.StreamingContext@220723b2\nssc: org.apache.spark.streaming.StreamingContext \u003d org.apache.spark.streaming.StreamingContext@220723b2\ncassandraConfig: scala.collection.immutable.Map[String,String] \u003d Map(keyspace -\u003e fluxcapacitor, table -\u003e real_time_likes)\nlikeStream: org.apache.spark.streaming.dstream.InputDStream[(String, String)] \u003d org.apache.spark.streaming.kafka.DirectKafkaInputDStream@46142849\n"
      },
      "dateCreated": "Jun 26, 2015 9:01:42 PM",
      "dateStarted": "Oct 6, 2015 11:18:25 PM",
      "dateFinished": "Oct 6, 2015 11:18:36 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Setup the Stream Data Transformations and Actions (Append to Cassandra Table)",
      "text": "import org.apache.spark.sql.SaveMode\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.streaming.Time\n\nlikeStream.foreachRDD{\n  (rdd: RDD[(String,String)], batchTime: Time) \u003d\u003e {\n      // convert each RDD from the batch into a DataFrame\n      val df \u003d rdd.toDF(\"from_user_id\", \"to_user_id\").select($\"from_user_id\", $\"to_user_id\")\n      \n      // add the batch time to the DataFrame\n      val dfWithBatchTime \u003d df.withColumn(\"batch_time\", lit(batchTime.milliseconds))\n      \n      // save the DataFrame to Cassandra\n      dfWithBatchTime.write.format(\"org.apache.spark.sql.cassandra\")\n        .mode(SaveMode.Append)\n        .options(cassandraConfig)\n        .save()\n  }\n}",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435352637874_125200642",
      "id": "20150626-210357_701410267",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.sql.SaveMode\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.streaming.Time\n"
      },
      "dateCreated": "Jun 26, 2015 9:03:57 PM",
      "dateStarted": "Oct 6, 2015 11:18:35 PM",
      "dateFinished": "Oct 6, 2015 11:18:37 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Start the Stream",
      "text": "ssc.start()",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435811421871_1604917400",
      "id": "20150702-043021_1434265086",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jul 2, 2015 4:30:21 AM",
      "dateStarted": "Oct 6, 2015 11:18:37 PM",
      "dateFinished": "Oct 6, 2015 11:18:38 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Uncomment To stop the stream",
      "text": "//ssc.stop(stopSparkContext\u003dfalse, stopGracefully\u003dfalse)",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435900392138_1989524513",
      "id": "20150703-051312_1037224009",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Jul 3, 2015 5:13:12 AM",
      "dateStarted": "Oct 6, 2015 11:18:38 PM",
      "dateFinished": "Oct 6, 2015 11:18:38 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1436047416200_1602967377",
      "id": "20150704-220336_100190094",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Jul 4, 2015 10:03:36 PM",
      "dateStarted": "Oct 6, 2015 11:18:38 PM",
      "dateFinished": "Oct 6, 2015 11:18:38 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Likes 0: Start Kafka Streaming Server (Optional)",
  "id": "2ASK4UQ3M",
  "angularObjects": {
    "2AR33ZMZJ": [],
    "2AS9P7JSA": [],
    "2ARR8UZDJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}
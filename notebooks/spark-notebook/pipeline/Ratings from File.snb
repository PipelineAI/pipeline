{
  "metadata": {
    "name": "Ratings from File",
    "user_save_timestamp": "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp": "1970-01-01T00:00:00.000Z",
    "language_info": {
      "name": "scala",
      "file_extension": "scala",
      "codemirror_mode": "text/x-scala"
    },
    "trusted": true,
    "customLocalRepo": "/root/.ivy2",
    "customRepos": null,
    "customDeps": [
      "com.datastax.spark:spark-cassandra-connector_2.10:1.4.0-M3",
      "org.apache.spark:spark-streaming-kafka_2.10:1.4.1",
      "org.apache.spark % spark-graphx_2.10 % 1.4.1",
      "- org.apache.spark % spark-core_2.10 % _",
      "- org.apache.spark % spark-streaming_2.10 % _",
      "- org.apache.hadoop % _ % _"
    ],
    "customImports": null,
    "customSparkConf": {
      "spark.cassandra.connection.host": "127.0.0.1",
      "spark.master": "spark://127.0.0.1:7077",
      "spark.executor.cores": "2",
      "spark.executor.memory": "1024m",
      "spark.cores.max": "2",
      "spark.eventLog.enabled": "true",
      "spark.eventLog.dir": "logs/spark"
    }
  },
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Creating the context to use `DataFrame`"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "import org.apache.spark.sql._\nval sqlContext = new SQLContext(sparkContext)\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Load the rating dataset (cold data)"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "val ratingsDF = sqlContext.read.format(\"json\").load(\"file:/root/pipeline/datasets/dating/ratings.json.bz2\")\n()",
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": ":markdown\nThere are ${ratingsDF.count} ratings",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's chek the leading ones"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "widgets.TableChart(ratingsDF, maxPoints=25)",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### It's a graph"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can create structures representing the ratings as `Edge`s and the raters as `Node`s."
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "val edges = ratingsDF.rdd.zipWithIndex.map(r => Edge(r._2, (r._1.getLong(0), r._1.getLong(2)), r._1.getLong(1)))\nval nodes = edges.flatMap(e => List(e.ends._1, e.ends._2)).distinct.map(x => Node(x, \"\"))\n()",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "What about plotting sample of that graph"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "val gs = new java.io.Serializable {\n  val ed = edges.sample(false, 0.00001).collect.toList\n  val nd = ed.flatMap(e => List(e.ends._1, e.ends._2)).distinct.map(x => Node(x, \"\"))\n  @transient val allG = ed :::nd\n  @transient val plot = widgets.GraphChart(allG, maxPoints=allG.size)\n}.plot",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Quick look at the distribution of the number of ratings"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### First independently of the gender"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The following counts the ratings per rater."
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "val ft = ratingsDF.groupBy(\"fromUserId\").agg(count(\"toUserId\").as(\"cnt\")).orderBy($\"cnt\".desc)",
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": ":markdown\nThere are actually ${ft.count} raters",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Quick glance at the distribution of the rating freaks"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "widgets.LineChart(ft.select(\"cnt\").rdd.map(_.getLong(0)).take(100), fields=Some((\"X\", \"Y\")), maxPoints=100)",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### What about the distribution within genders"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### First we load the cold data"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "val genderDF = sqlContext.read.format(\"json\").load(\"file:/root/pipeline/datasets/dating/gender.json.bz2\")",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Looking at number of ratings per gender (joining)"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "val withGender = ft.join(genderDF, ft(\"fromUserId\") === genderDF(\"id\"))\ndef inG(g:String) = withGender.filter($\"gender\" === g).orderBy($\"cnt\".desc).select(\"cnt\").rdd.map(_.getLong(0)).take(100)\nval fems = inG(\"F\")\nval mals = inG(\"M\")\nval others = inG(\"U\")\n\nwidgets.LineChart(fems, fields=Some((\"X\", \"Y\")), maxPoints=100) ++ \n  widgets.LineChart(mals, fields=Some((\"X\", \"Y\")), maxPoints=100) ++ \n  widgets.LineChart(others, fields=Some((\"X\", \"Y\")), maxPoints=100)",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### It's definitely a Graph(X)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Hence we can create a spark Graph instance using the ratings and gender datasets."
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "import org.apache.spark.graphx.{Edge=>GEdge, _}\nval gnodes = nodes.map(_.id).toDF\nval xVertices = gnodes.join(genderDF, gnodes(\"_1\") === genderDF(\"id\")).select(gnodes(\"_1\"), genderDF(\"gender\")).map(r => (r.getLong(0), r.getString(1)))\nval xEdges = edges.map(e => org.apache.spark.graphx.Edge(e.ends._1, e.ends._2, e.value))\nval graph = Graph(xVertices, xEdges)",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### How are those raters performing with their buddies: PageRank"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "val pg = graph.ops.pageRank(0.001)",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "What does that look like?"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "pg.vertices.take(10)",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The schema might be interesting to check before hacking that one."
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "val pgv = pg.vertices.toDF\npgv.schema",
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Check the PageRank distributions within genders"
    },
    {
      "metadata": {
        "trusted": true,
        "input_collapsed": false,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "val bestG = pgv.join(genderDF, pgv(\"_1\") === genderDF(\"id\"))\n\nimport notebook.front.third.wisp._\ndef bestGInG(g:String) = bestG.filter($\"gender\" === g).orderBy($\"_2\".desc).select($\"_2\").map(_.getDouble(0)).zipWithIndex.map(_.swap).take(1000).toList\nval bf = bestGInG(\"F\")\nval bm = bestGInG(\"M\")\nval bu = bestGInG(\"U\")\nPlot(Seq(Pairs(bf, \"line\"), Pairs(bm, \"line\"), Pairs(bu, \"line\")))",
      "outputs": []
    }
  ],
  "nbformat": 4
}
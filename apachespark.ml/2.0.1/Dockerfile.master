FROM fluxcapacitor/package-spark-2.0.1

WORKDIR /root

# Install Python with conda
RUN wget -q https://repo.continuum.io/miniconda/Miniconda3-4.1.11-Linux-x86_64.sh -O /tmp/miniconda.sh  && \
    echo '874dbb0d3c7ec665adf7231bbb575ab2 */tmp/miniconda.sh' | md5sum -c - && \
    bash /tmp/miniconda.sh -f -b -p /opt/conda && \
    /opt/conda/bin/conda install --yes python=3.5 sqlalchemy tornado jinja2 traitlets requests pip && \
    /opt/conda/bin/pip install --upgrade pip && \
    rm /tmp/miniconda.sh

ENV \
  PATH=/opt/conda/bin:$PATH 

RUN \
  conda install --yes scikit-learn numpy scipy matplotlib pandas seaborn

RUN \
  conda install --yes -c conda-forge py4j

# Overcomes current limitation with conda matplotlib (1.5.1)
RUN \
  apt-get update \
  && apt-get install -y python-qt4

ENV \
  TENSORFLOW_VERSION=0.12.1

RUN \
#  pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-$TENSORFLOW_VERSION-cp35-cp35m-linux_x86_64.whl
  conda install -c conda-forge tensorflow=$TENSORFLOW_VERSION

RUN \
  conda install -c r r-essentials

#RUN \
#  echo "deb http://cran.rstudio.com/bin/linux/ubuntu trusty/" >> /etc/apt/sources.list \
#  && gpg --keyserver keyserver.ubuntu.com --recv-key E084DAB9 \
#  && gpg -a --export E084DAB9 | apt-key add - \
#  && apt-get update \
#  && apt-get install -y r-base \
#  && apt-get install -y r-base-dev

# Required by Tensorflow
ENV \
  HADOOP_HDFS_HOME=${HADOOP_HOME}

#ENV \
#  CLASSPATH=$(${HADOOP_HDFS_HOME}/bin/hadoop classpath --glob)

ENV \
  LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${JAVA_HOME}/jre/lib/amd64/server

COPY run.master run
COPY demos/ demos/

# Expose Spark Master Port for Web Admin UI
EXPOSE 6060 

# Expose Spark Master Port for REST API
EXPOSE 6066

# Expose Spark Master Port for Spark Workers
EXPOSE 7077

# Expose Spark Job Admin Ports
EXPOSE 4040 4041 4042 4043 4044

CMD ["supervise", "."]

apiVersion: apps/v1
kind: StatefulSet
metadata:
  creationTimestamp: 2019-02-13T01:10:38Z
  generation: 1
  labels:
    app: airflow
    chart: airflow-0.15.0
    component: worker
    heritage: Tiller
    release: airflow
  name: airflow-worker
  namespace: default
spec:
  podManagementPolicy: Parallel
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: airflow
      component: worker
      release: airflow
  serviceName: airflow-worker
  template:
    metadata:
      annotations:
        checksum/config: b607daf1e003a84b9b8d142faa21fc1938b33e10c9f2297c9d72a0c1d8fdafa6
        configmap.fabric8.io/update-on-change: airflow-env
      creationTimestamp: null
      labels:
        app: airflow
        component: worker
        release: airflow
    spec:
      containers:
      - args:
        - bash
        - -c
        - |
          echo 'waiting 60s...' && sleep 60 && mkdir -p /usr/local/airflow/.local/bin && export PATH=/usr/local/airflow/.local/bin:$PATH && echo 'executing worker...' && airflow worker
        env:
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              key: postgresUser
              name: airflow
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              key: postgresPassword
              name: airflow
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              key: redisPassword
              name: airflow
        envFrom:
        - configMapRef:
            name: airflow-env
        image: stibbons31/docker-airflow-dev:2.0dev
        imagePullPolicy: IfNotPresent
        name: airflow-worker
        ports:
        - containerPort: 8793
          name: wlog
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - name: airflow-token-8grhd
          mountPath: /var/run/secrets/kubernetes.io/serviceaccount
          readOnly: true
        - name: dags-data 
          mountPath: /mnt/pipelineai/users
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: airflow
      serviceAccountName: airflow
      terminationGracePeriodSeconds: 30
      volumes:
#      - name: dags-data
#        emptyDir: {}
      - name: dags-data
        flexVolume:
          driver: ceph.rook.io/rook
          fsType: ceph
          options:
            fsName: pipelineai-fs # name of the filesystem specified in the filesystem CRD.
            clusterNamespace: default # namespace where the Rook cluster is deployed
            # by default the path is /, but you can override and mount a specific path of the filesystem by using the path attribute
            # the path must exist on the filesystem, otherwise mounting the filesystem at that path will fail
            path: users/
  updateStrategy:
    type: RollingUpdate
